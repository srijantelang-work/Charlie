# Charlie 
### Friendly, Reliable, Intelligent Digital Assistant

Charlie  is a powerful, open-source AI assistant designed for real-time interaction and system integration. This next-generation release focuses on dramatic performance improvements and enhanced capabilities while maintaining a completely open-source architecture.

## üöÄ Core Features

<details>
<summary><b>Advanced Voice Interface</b></summary>

- Real-time voice synthesis using StyleTTS2
- Fast transcription with faster-whisper
- Voice interrupt capability during responses
</details>

<details>
<summary><b>Intelligent Processing</b></summary>

- Local LLM processing via llama.cpp
- Advanced memory systems:
  - Context-aware short-term memory
  - Long-term conversation storage
  - Automatic importance detection
  - Tag-based memory retrieval
- Natural language command parsing
</details>

<details>
<summary><b>Memory System</b></summary>

- Contextual conversation tracking
- Automatic importance detection
- Personal preference learning
- Tag-based memory organization:
  - Personal facts
  - Preferences
  - Temporal information
  - Tasks and reminders
- Conversation timeout management
- Memory persistence across sessions
</details>

<details>
<summary><b>System Integration</b></summary>

- Device control capabilities
- Sensor data processing
- Task automation
- External service integration
</details>

## üèóÔ∏è Architecture

```
Charlie Core
‚îú‚îÄ‚îÄ Voice Interface
‚îÇ   ‚îú‚îÄ‚îÄ StyleTTS2 (Speech Synthesis)
‚îÇ   ‚îî‚îÄ‚îÄ faster-whisper (Speech Recognition)
‚îú‚îÄ‚îÄ Brain
‚îÇ   ‚îú‚îÄ‚îÄ LocalAI/llama.cpp
‚îÇ   ‚îú‚îÄ‚îÄ Memory System
‚îÇ   ‚îî‚îÄ‚îÄ Command Parser
‚îú‚îÄ‚îÄ Skills System
‚îÇ   ‚îú‚îÄ‚îÄ Core Skills
‚îÇ   ‚îî‚îÄ‚îÄ Custom Plugins
‚îî‚îÄ‚îÄ System Integration
    ‚îú‚îÄ‚îÄ Device Control
    ‚îú‚îÄ‚îÄ Sensor Processing
    ‚îú‚îÄ‚îÄ Task Automation
    ‚îî‚îÄ‚îÄ External Services
```

## üõ†Ô∏è Tech Stack

- **FastAPI/gRPC**: Microservices communication
- **Redis**: Real-time state management
- **StyleTTS2**: Voice synthesis
- **faster-whisper**: Speech recognition
- **llama.cpp**: Local LLM inference
- **Home Assistant**: Device control integration


## üö¶ Getting Started

```bash
# Clone the repository
git clone https://github.com/your-username/charlie.git

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Unix
venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Start Charlie
python charlie.py
```

## üîß Configuration

Create a `config.yaml` file in the root directory:

```yaml
voice:
  engine: "styletts2"
  language: "en"
  
llm:
  model: "llama3.2-3b"
  quantization: "q4_K_M"
  
system:
  parallel_processing: true
  cache_enabled: true
  memory:
    context_size: 10
    conversation_timeout: 300
    persistence: true
    tags:
      - personal
      - preference
      - temporal
      - task
      - fact
```

## ü§ù Required Model Files

The following model files need to be downloaded and placed in the `models/` directory:

```
models/
‚îú‚îÄ‚îÄ faster-whisper-base/
‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îú‚îÄ‚îÄ model.bin
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ   ‚îî‚îÄ‚îÄ vocabulary.txt
‚îî‚îÄ‚îÄ llama/
    ‚îî‚îÄ‚îÄ llama-3.2-3B-instruct-uncensored.gguf
```

### Model Downloads
- **Faster Whisper**: Download the base model from [HuggingFace](https://huggingface.co/guillaumekln/faster-whisper-base)
- **Llama**: Download the quantized model from [HuggingFace](https://huggingface.co/TheBloke/Llama-2-3B-GGUF)

> Note: Due to size limitations, model files are not included in this repository. Please download them separately using the links above.

## üôè Acknowledgments


---

<p align="center">Made with a dream of matching Tony Stark </p>
